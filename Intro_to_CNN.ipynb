{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Intro to CNN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franciscodlsb/MLSS2020TU/blob/master/Intro_to_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOGRsRnHZN-f",
        "colab_type": "text"
      },
      "source": [
        "# Disclaimer\n",
        "* Based on Google Tensorflow Tutorial as the Base Code\n",
        "* Edited by Vincent Tatan for Intro to CNN Lessons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp0rQsiTls_n",
        "colab_type": "text"
      },
      "source": [
        "# Base Code\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Image classification and Building Simple CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gN7G9GFmVrVY"
      },
      "source": [
        "This tutorial shows how to classify cats or dogs from images. It builds an image classifier using a `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`. You will get some practical experience and develop intuition for the following concepts:\n",
        "\n",
        "* Building _data input pipelines_ using the `tf.keras.preprocessing.image.ImageDataGenerator` class to efficiently work with data on disk to use with the model.\n",
        "* _Overfitting_ —How to identify and prevent it.\n",
        "* _Data augmentation_ and _dropout_ —Key techniques to fight overfitting in computer vision tasks to incorporate into the data pipeline and image classifier model.\n",
        "\n",
        "This tutorial follows a basic machine learning workflow:\n",
        "\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build the model\n",
        "4. Train the model\n",
        "5. Test the model\n",
        "6. Improve the model and repeat the process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## Import Tensorflow packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VddxeYBEVrVZ"
      },
      "source": [
        "Let's start by importing the required packages. The `os` package is used to read files and directory structure, NumPy is used to convert python list to numpy array and to perform required matrix operations and `matplotlib.pyplot` to plot the graph and display images in the training and validation data.\n",
        "\n",
        "At the time of writing, Colab has TensorFlow version 1.x installed by default. TensorFlow 2.x is much easier to use, so let's start with that. To switch to 2.x we'll use the magic command below. Note, you can also install TensorFlow by using pip, but in Colab, the magic command is faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jlchl4x2VrVg"
      },
      "source": [
        "Import Tensorflow and the Keras classes needed to construct our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nmMfiSBcXZST",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L1WtoaOHVrVh",
        "colab": {}
      },
      "source": [
        "# We'll use Keras as the TensorFlow's user-friendly API to deep learning\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        "Begin by downloading the dataset. This tutorial uses a filtered version of <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs Cats</a> dataset from Kaggle. Download the archive version of the dataset and store it in the \"/tmp/\" directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C1nqr-CYY6uw",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Giv0wMQzVrVw"
      },
      "source": [
        "The dataset has the following directory structure:\n",
        "\n",
        "<pre>\n",
        "<b>cats_and_dogs_filtered</b>\n",
        "|__ <b>train</b>\n",
        "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
        "|__ <b>validation</b>\n",
        "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VpmywIlsVrVx"
      },
      "source": [
        "After extracting its contents, assign variables with the proper file path for the training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sRucI3QqVrVy",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Utv3nryxVrV0",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZdrHHTy2VrV3"
      },
      "source": [
        "### Understand the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LblUYjl-VrV3"
      },
      "source": [
        "Let's look at how many cats and dogs images are in the training and validation directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vc4u8e9hVrV4",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g4GGzGt0VrV7",
        "colab": {}
      },
      "source": [
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Lp-0ejxOtP1"
      },
      "source": [
        "For convenience, set up variables to use while pre-processing the dataset and training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3NqNselLVrWA",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "INn-cOn1VrWC"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Jfk6aSAVrWD"
      },
      "source": [
        "Format the images into appropriately pre-processed floating point tensors before feeding to the network:\n",
        "\n",
        "1. Read images from the disk.\n",
        "2. Decode contents of these images and convert it into proper grid format as per their RGB content.\n",
        "3. Convert them into floating point tensors.\n",
        "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values. It's important that the training set and the testing set are preprocessed in the same way.\n",
        "\n",
        "Fortunately, all these tasks can be done with the `ImageDataGenerator` class provided by `tf.keras`. It can read images from disk and preprocess them into proper tensors. It will also set up generators that convert these images into batches of tensors—helpful when training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "syDdF_LWVrWE",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RLciCR_FVrWH"
      },
      "source": [
        "After defining the generators for training and validation images, the `flow_from_directory` method load images from the disk, applies rescaling, and resizes the images into the required dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pw94ajOOVrWI",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2oUoKUzRVrWM",
        "colab": {}
      },
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hyexPJ8CVrWP"
      },
      "source": [
        "### Visualize training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "60CnhEL4VrWQ"
      },
      "source": [
        "Visualize the training images by extracting a batch of images from the training generator—which are 128 images in this example—then plot five of them with `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3f0Z7NZgVrWQ",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "49weMt5YVrWT"
      },
      "source": [
        "The `next` function returns a batch from the dataset. The return value of `next` function is in form of `(x_train, y_train)` where x_train is training features and y_train, its labels. Discard the labels to only visualize the training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JMt2RES_VrWU",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d_VVg_gEVrWW",
        "colab": {}
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b5Ej-HLGVrWZ"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj9web67aK5V",
        "colab_type": "text"
      },
      "source": [
        "### What does a layer do?\n",
        "\n",
        "Layers extract data representations fed to them\n",
        "1. First layer: receives pixel values as input. Learning to detect edges as combinations of pixel\n",
        "2. Second layer: Receives edges as inputs and detect lines\n",
        "3. n layer after: detect shapes and high level features.\n",
        "\n",
        "Deep learning refers to this depth which consist of chaining together dense layers. [tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense), have parameters that are initialized randomly, then tuned (or learned) during training by gradient descent.\n",
        "\n",
        "The model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it that is activated by a `relu` activation function. Neural networks are made up of layers. Here, you'll define the layers, and assemble them into a model. We will start with a single Dense layer. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F15-uwLPVrWa",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2,activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR5T65Rha38E",
        "colab_type": "text"
      },
      "source": [
        "[tf.keras.layers.Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten), flattens 2-D Array into 1-D Array. \n",
        "\n",
        "Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data. This is necessary since Dense layers require 1-D array as input.\n",
        "\n",
        "After the pixels are flattened, this model consists of a single Dense layer. This is a densely connected, or fully connected (FCL). \n",
        "\n",
        "The Dense last layer has 1 neurons with sigmoid activation \n",
        "\n",
        "After classifying an image, each neuron will contains a score that indicates the probability that the current image belongs to one of the 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PI5cdkMQVrWc"
      },
      "source": [
        "### Compile the model\n",
        "\n",
        "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
        "\n",
        "*Loss function* — This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
        "\n",
        "*Optimizer* — This is how the model is updated based on the data it sees and its loss function.\n",
        "\n",
        "*Metrics* — Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.\n",
        "\n",
        "For this tutorial we choose *ADAM* optimizer and *binary cross entropy* loss function. To view training and validation accuracy for each training epoch, pass the `metrics` argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Mg7_TXOVrWd",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2YmQZ3TAVrWg"
      },
      "source": [
        "### Model summary\n",
        "\n",
        "View all the layers of the network using the model's `summary` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vtny8hmBVrWh",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N06iqE8VVrWj"
      },
      "source": [
        "### Train the model\n",
        "Training the neural network model requires the following steps:\n",
        "\n",
        "1. Feed the training data to the model. In this example, the training data is in the ```train_images``` and ```train_labels``` arrays.\n",
        "\n",
        "1. The model learns to associate images and labels.\n",
        "\n",
        "1. You ask the model to make predictions about a test set—in this example, the ```test_images``` array.\n",
        "\n",
        "1. Verify that the predictions match the labels from the ```test_labels``` array.\n",
        "\n",
        "To begin training, call the ```model.fit``` method — so called because it \"fits\" the model to the training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KSF2HqhDVrWk",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ojJNteAGVrWo"
      },
      "source": [
        "### Visualize training results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LZPYT-EmVrWo"
      },
      "source": [
        "Now visualize the results after training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K6oA77ADVrWp",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(24, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kDnr50l2VrWu"
      },
      "source": [
        "As you can see from the plots, training accuracy and validation accuracy are off by large margin and the model has achieved only around **70%** accuracy on the validation set.\n",
        "\n",
        "This gap between training accuracy and test accuracy represents overfitting. Overfitting is when a machine learning model performs worse on new, previously unseen inputs than on the training data. \n",
        "\n",
        "An overfitted model \"memorizes\" the training data—with less accuracy on testing data.\n",
        "\n",
        "Let's look at what went wrong and try to increase overall performance of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rLO7yhLlVrWu"
      },
      "source": [
        "# Managing Overfitting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hNyx3Lp4VrWv"
      },
      "source": [
        "In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 70% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable—a sign of *overfitting*.\n",
        "\n",
        "When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples—to an extent that it negatively impacts the performance of the model on new examples. This phenomenon is known as overfitting. It means that the model will have a difficult time generalizing on a new dataset.\n",
        "\n",
        "There are multiple ways to fight overfitting in the training process. In this tutorial, you'll use *data augmentation* and add *dropout* to our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UOoVpxFwVrWy"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wn_QLciWVrWy"
      },
      "source": [
        "Overfitting generally occurs when there are a small number of training examples. One way to fix this problem is to augment the dataset so that it has a sufficient number of training examples. Data augmentation takes the approach of generating more training data from existing training samples by augmenting the samples using random transformations that yield believable-looking images. The goal is the model will never see the exact same picture twice during training. This helps expose the model to more aspects of the data and generalize better.\n",
        "\n",
        "Implement this in `tf.keras` using the `ImageDataGenerator` class. Pass  different transformations to the dataset and it will take care of applying it during the training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2uJ1G030VrWz"
      },
      "source": [
        "### Augment and visualize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hvX7hHlgVrW0"
      },
      "source": [
        "We can use a technique called \"data augmentation\" to increase the size of the training set, by generating new examples from existing ones by applying random transformations (for example, rotation).\n",
        "\n",
        "This is especially effective when working with images. For example, our training set may only contain images of cats that are right side up. If our validation set contains images of cats that are upside down, our model may have trouble classifying them correctly. \n",
        "\n",
        "Data augmentation is built into the ImageDataGenerator. You can specifiy different transformations, and it will take care of applying then during the training.\n",
        "\n",
        "Begin by applying random horizontal flip augmentation to the dataset and see how individual images look like after the transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rlVj6VqaVrW0"
      },
      "source": [
        "### Apply horizontal flip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xcdvx4TVVrW1"
      },
      "source": [
        "Pass `horizontal_flip` as an argument to the `ImageDataGenerator` class and set it to `True` to apply this augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bi1_vHyBVrW2",
        "colab": {}
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zvwqmefgVrW3",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zJpRSxJ-VrW7"
      },
      "source": [
        "Take one sample image from the training examples and repeat it five times so that the augmentation is applied to the same image five times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RrKGd_jjVrW7",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EvBZoQ9xVrW9",
        "colab": {}
      },
      "source": [
        "# Re-use the same custom plotting function defined and used\n",
        "# above to visualize the training images\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i7n9xcqCVrXB"
      },
      "source": [
        "### Randomly rotate the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qXnwkzFuVrXB"
      },
      "source": [
        "Let's take a look at a different augmentation called rotation and apply 45 degrees of rotation randomly to the training examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1zip35pDVrXB",
        "colab": {}
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kVoWh4OIVrXD",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wmBx8NhrVrXK",
        "colab": {}
      },
      "source": [
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FOqGPL76VrXM"
      },
      "source": [
        "### Apply zoom augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NvqXaD8BVrXN"
      },
      "source": [
        "Apply a zoom augmentation to the dataset to zoom images up to 50% randomly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tGNKLa_YVrXR",
        "colab": {}
      },
      "source": [
        "# zoom_range from 0 - 1 where 1 = 100%.\n",
        "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5) # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VOvTs32FVrXU",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-KQWw8IZVrXZ",
        "colab": {}
      },
      "source": [
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "usS13KCNVrXd"
      },
      "source": [
        "### Put it all together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OC8fIsalVrXd"
      },
      "source": [
        "Apply all the previous augmentations. Here, you applied rescale, 45 degree rotation, width shift, height shift, horizontal flip and zoom augmentation to the training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gnr2xujaVrXe",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K0Efxy7EVrXh",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AW-pV5awVrXl"
      },
      "source": [
        "Visualize how a single image would look five different times when passing these augmentations randomly to the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z2m68eMhVrXm",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J8cUd7FXVrXq"
      },
      "source": [
        "### Create validation data generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a99fDBt7VrXr"
      },
      "source": [
        "Generally, only apply data augmentation to the training examples. In this case, only rescale the validation images and convert them into batches using `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "54x0aNbKVrXr",
        "colab": {}
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1PCHKzI8VrXv",
        "colab": {}
      },
      "source": [
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yQGhdqHFVrXx"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Iq5TAH_VrXx"
      },
      "source": [
        "Another technique to reduce overfitting is to introduce *dropout* to the network. It is a form of *regularization* that forces the weights in the network to take only small values, which makes the distribution of weight values more regular and the network can reduce overfitting on small training examples. Dropout is one of the regularization technique used in this tutorial\n",
        "\n",
        "When you apply dropout to a layer it randomly drops out (set to zero) number of output units from the applied layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
        "\n",
        "When appling 0.1 dropout to a certain layer, it randomly kills 10% of the output units in each training epoch.\n",
        "\n",
        "Create a network architecture with this new dropout feature and apply it to different convolutions and fully-connected layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DyxxXRmVVrXy"
      },
      "source": [
        "## Creating a new network with Dropouts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Ba2LjtkVrXy"
      },
      "source": [
        "Here, you apply dropout to first and last max pool layers. Applying dropout will randomly set 20% of the neurons to zero during each training epoch. This helps to avoid overfitting on the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2fjio8EsVrXz",
        "colab": {}
      },
      "source": [
        "model_new = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', \n",
        "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tpTgIxWAVrX0"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1osvc_iTVrX1"
      },
      "source": [
        "After introducing dropouts to the network, compile the model and view the layers summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OkIJhS-WVrX1",
        "colab": {}
      },
      "source": [
        "model_new.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model_new.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7KiDshEUVrX6"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFj0oVqVVrX6"
      },
      "source": [
        "After successfully introducing data augmentations to the training examples and adding dropouts to the network, train this new network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GWxHs_luVrX7",
        "colab": {}
      },
      "source": [
        "history = model_new.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bbdyqZdxVrYA"
      },
      "source": [
        "### Visualize the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OgvF2nt7OtR7"
      },
      "source": [
        "Visualize the new model after training, you can see that there is significantly less overfitting than before. The accuracy should go up after training the model for more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7BTeMuNAVrYC",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(6, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S04SyLLuZVs6",
        "colab_type": "text"
      },
      "source": [
        "# Advanced: Transfer Learning [EXTRA]\n",
        "\n",
        "This notebook contains the code sample found in Chapter 5, Section 3 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content.\n",
        "\n",
        "Common approach is to leverage small image datasets for a pre-trained network. The spatial feature hierarchy will act as generic model of our visual world. This will prove very useful and can be repurposed easily. Such as one might use ImageNet then repurpose it for IKEA Furniture Detection. It makes things easier and robust for small dataset problem.\n",
        "\n",
        "In our case, we will consider a large convnet trained on the ImageNet dataset (1.4 million labeled images and 1000 different classes). \n",
        "\n",
        "ImageNet has animal classes. But let us use this in our cat vs dog classification problem.\n",
        "\n",
        "We will use the VGG16 architecture, developed by Karen Simonyan and Andrew Zisserman in 2014, a simple and widely used convnet architecture \n",
        "for ImageNet. \n",
        "\n",
        "\n",
        "Other models include VGG, ResNet, Inception, Inception-ResNet,\n",
        "Xception. You will get used to them, as they will come up frequently if you keep doing deep learning for computer vision.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwVv3rpakWkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The VGG16 model, among others, comes pre-packaged with Keras. You can import it from the `keras.applications` module. Here's the list of \n",
        "# image classification models (all pre-trained on the ImageNet dataset) that are available as part of `keras.applications`:\n",
        "\n",
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(150, 150, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU6g6rjtkdaM",
        "colab_type": "text"
      },
      "source": [
        "We passed three arguments:\n",
        "\n",
        "* `weights`, specify which weight checkpoint initializes the model from\n",
        "* `include_top`, which refers to including or not the densely-connected classifier on top of the network. By default, this \n",
        "densely-connected classifier would correspond to the 1000 classes from ImageNet. \n",
        "* `input_shape`, the shape of the image tensors that we will feed to the network. This argument is purely optional: if we don't pass it, \n",
        "then the network will be able to process inputs of any size.\n",
        "\n",
        "Here's the detail of the architecture of the VGG16 convolutional base: it's very similar to the simple convnets that you are already \n",
        "familiar with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac3KjHsMkt8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWGeAW8YlPJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(2,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAlWddutl-bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTlSZikAmLck",
        "colab_type": "text"
      },
      "source": [
        "## Freezing the conv_base\n",
        "This is important so that we can prevent the conv_base weights from getting updated during training. Since Dense Layers are randomly initialized. Large weight updates would be propagated through network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OXszTuRmeLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRBibUolmFNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQxplquPmGUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYCZSRQOm-DY",
        "colab_type": "text"
      },
      "source": [
        "## Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiS83aaWmvg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRVDMlsknGDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(6, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "print('loss: {}'.format(round(loss[-1],4)))\n",
        "print('acc: {}'.format(round(acc[-1],4)))\n",
        "\n",
        "print('val_loss: {}'.format(round(val_loss[-1],4)))\n",
        "print('val_acc: {}'.format(round(val_acc[-1],4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N_ONblMdHfk",
        "colab_type": "text"
      },
      "source": [
        "# An advanced example: DeepDream [EXTRA]\n",
        "\n",
        "This instruction will be added as the author is researching and adding best ways to explain DeepDream.\n",
        "\n",
        "DeepDream is an experiment to visualize some of the features a convolutional neural network has learned to detect. This part of tutorial aims to inspire and fascinate you on what you can explore with Deep Learning\n",
        "\n",
        "Normally, we use gradient descent to minimize classification loss. In CNN, we adjust the filter weights. In DeepDream, we start with a pretrained CNN with fixed filters. Then we use gradient descent to activate the filters. We will generate examples based on these filters as textures.\n",
        "\n",
        "The first part is called the \"convolutional base\" of the model. In the case of \n",
        "convnets, \"feature extraction\" will simply consist of taking the convolutional base of a previously-trained network, running the new data \n",
        "through it, and training a new classifier on top of the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fltxBfpwd2py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0im-WBzrdJlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download(url, target_size=None):\n",
        "  name = url.split('/')[-1]\n",
        "  image_path = tf.keras.utils.get_file(name, origin=url)\n",
        "  return tf.keras.preprocessing.image.load_img(image_path, target_size)\n",
        "\n",
        "def show(img):\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.grid(False)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "original_img = download(url, target_size=[225, 375])\n",
        "original_img = np.array(original_img)\n",
        "show(original_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aBcMfYZd8K2",
        "colab_type": "text"
      },
      "source": [
        "## Rescale pixel values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRK-wiYed5-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(img):\n",
        "  \"\"\" Convert RGB values from [0, 255] to [-1, 1] \"\"\"\n",
        "  img = tf.cast(img, tf.float32)\n",
        "  img /= 128.0\n",
        "  img -= 1.\n",
        "  return img\n",
        "\n",
        "def unprocess(img):\n",
        "  \"\"\" Undo the preprocessing above \"\"\"\n",
        "  img = 255 * (img + 1.0) / 2.0\n",
        "  return tf.cast(img, tf.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzQg2ykQd7m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base = tf.keras.applications.InceptionV3(weights='imagenet', \n",
        "                                              include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWfmsXnzeGYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2HjejfSeBag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary() will induce what layers you can activate/deactivate.\n",
        "names = ['mixed2', 'mixed3', 'mixed4', 'mixed5']\n",
        "layers = [conv_base.get_layer(name).output for name in names]\n",
        "model = tf.keras.Model(inputs=conv_base.input, outputs=layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5jCrCMGeN5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We write a loss function which activates our layers as if they were images\n",
        "def calc_loss(img):\n",
        "  img_batch = tf.expand_dims(img, axis=0)\n",
        "  layer_activations = model(img_batch)\n",
        "  losses = [tf.math.reduce_mean(act) for act in layer_activations]\n",
        "  return tf.reduce_sum(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t2ytY0ZeUzd",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Ascent to activate the layers progressively\n",
        "In Deep dream, you aim to maximize the activation of the layers by modifying images but leaving network weights fixed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zzadawWemAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def step(img, lr=0.001):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = calc_loss(img)\n",
        "\n",
        "  gradients = tape.gradient(loss, img)\n",
        "  gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "\n",
        "  # Because the gradients are in the same shape \n",
        "  # as the image, we can directly add them to it!\n",
        "  img.assign_add(gradients * lr)\n",
        "  img.assign(tf.clip_by_value(img, -1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_fqWcIQen90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = tf.Variable(preprocess(original_img))\n",
        "\n",
        "steps = 1000\n",
        "for i in range(steps):\n",
        "  step(img)\n",
        "  if i % 200 == 0:\n",
        "    clear_output(wait=True)\n",
        "    print (\"Step {}\".format(i))\n",
        "    show(unprocess(img.numpy()))\n",
        "\n",
        "clear_output(wait=True)\n",
        "show(unprocess(img.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvC6fD46epGN",
        "colab_type": "text"
      },
      "source": [
        "You can find a complete example on the [website](https://www.tensorflow.org/tutorials/generative/deepdream) (which includes additional code to generate less noisy images), and you may also be interested in exploring a related technique [Neural Style Transfer](https://www.tensorflow.org/tutorials/generative/style_transfer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKpFWUilevcp",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "\n",
        "Tensorflow Tutorials\n",
        "- Twitter https://twitter.com/tensorflow\n",
        "- Blog http://blog.tensorflow.org/\n",
        "- YouTube https://www.youtube.com/tensorflow.\n",
        "\n",
        "Books\n",
        "* Deep Learning with Python\n",
        "* Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow"
      ]
    }
  ]
}